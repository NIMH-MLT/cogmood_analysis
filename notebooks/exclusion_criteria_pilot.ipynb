{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b40583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x1283d16a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from cogmood_analysis.load import load_task, boxcoxmask, nanboxcox, load_survey, proc_survey\n",
    "import cogmood_analysis.survey_helpers as sh\n",
    "from scipy.stats import boxcox\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "import json\n",
    "pl.Config(tbl_rows=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced7557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/nielsond/code/cogmood/data/20250611_pilot/good_task')\n",
    "out_dir = Path('/Users/nielsond/code/cogmood/data/20250611_pilot/to_model')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "task_data_dir = data_dir\n",
    "start_time = pl.Series(['2025-06-09 00:00:00']).str.to_datetime()[0]\n",
    "tasks = ['flkr', 'cab', 'rdm', 'bart']\n",
    "bad_dirs = ['.DS_Store']\n",
    "from_scratch = True\n",
    "\n",
    "#timing limits\n",
    "limits = {\n",
    "    'cab': (0.2, 2.5),\n",
    "    'flkr': (0, 3),\n",
    "    'rdm': (0, 3),\n",
    "    'bart': (0, 100)\n",
    "}\n",
    "\n",
    "# chance threshold\n",
    "# have to press pump on first trial of at least 24 of 36 balloons \n",
    "# for p = 0.032 < 0.05 responses are not at random\n",
    "# (23 is 0.066)\n",
    "bart_thresh = 24\n",
    "# cab\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "cab_thresh = 57\n",
    "cab_rt_thresh05 = 4.8\n",
    "cab_rt_thresh10 = 9.6\n",
    "#rdm\n",
    "# correct response on 105 out of 186 nonrandom trials\n",
    "# for p = 0.045 < 0.05 responses are not at random\n",
    "# (104 is 0.062)\n",
    "rdm_thresh = 105\n",
    "rdm_rt_thresh05 = 222 * 0.05\n",
    "rdm_rt_thresh10 = 222 * 0.1\n",
    "# flkr\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "flkr_thresh = 57\n",
    "flkr_rt_thresh05 = 4.8\n",
    "flkr_rt_thresh10 = 9.6\n",
    "\n",
    "corr_threshes = {\n",
    "    'bart': 24,\n",
    "    'cab': 57,\n",
    "    'rdm': 105,\n",
    "    'flkr': 57\n",
    "}\n",
    "# invert thresholds to get mimimum number passing\n",
    "rt05_threshes = {\n",
    "    'cab': 96 * 0.95,\n",
    "    'rdm': 222 * 0.95,\n",
    "    'flkr': 96 * 0.95\n",
    "}\n",
    "\n",
    "rt10_threshes = {\n",
    "    'cab': 96 * 0.9,\n",
    "    'rdm': 222 * 0.9,\n",
    "    'flkr': 96 * 0.9\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427fb52",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not from_scratch:\n",
    "    task_dat = {}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = pl.read_parquet(data_dir/f'{task_name}.parquet')\n",
    "\n",
    "    complete = []\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        expected_n = 2\n",
    "        if task_name== 'rdm':\n",
    "            expected_n = 3\n",
    "        tmp = (tdf.group_by('sub_id').n_unique()\n",
    "            .select(['sub_id', 'zrn']).with_columns(\n",
    "                (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "                ).select(['sub_id', f'has_all_{task_name}']))\n",
    "        complete.append(tmp)\n",
    "    complete = pl.concat(complete, how='align').with_columns(\n",
    "        has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    "    )\n",
    "\n",
    "    complete_subs = complete.filter('has_all').get_column('sub_id').to_list()\n",
    "else:\n",
    "    complete_subs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7343a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subids = sorted([dd.parts[-1] for dd in (data_dir).glob('*') if (dd.parts[-1] not in bad_dirs)])\n",
    "needed_subids = [sid for sid in all_subids if sid not in complete_subs]\n",
    "# go ahead and just drop all the needed_subids\n",
    "if not from_scratch:\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        task_dat[task_name] = tdf.filter(~pl.col('sub_id').is_in(needed_subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebfcaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/flkr_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/flkr_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/cab_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/cab_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/rdm_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/rdm_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/rdm_2.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/bart_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/bart.parquet/bart_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/flkr_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/flkr_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/cab_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/cab_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/rdm_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/rdm_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/rdm_2.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/bart_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/cab.parquet/bart_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/flkr_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/flkr_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/cab_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/cab_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/rdm_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/rdm_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/rdm_2.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/bart_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/flkr.parquet/bart_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/flkr_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/flkr_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/cab_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/cab_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/rdm_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/rdm_1.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/rdm_2.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/bart_0.zip\n",
      "/Users/nielsond/code/cogmood/data/20250611_pilot/good_task/rdm.parquet/bart_1.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 25 out of 56 | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1793697345974371s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 47 out of 56 | elapsed:    2.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 53 out of 56 | elapsed:    2.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.01884174346923828s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.033435821533203125s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 47 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 53 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.00859379768371582s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.030567169189453125s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 84 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 60 out of 84 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 69 out of 84 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 78 out of 84 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 84 out of 84 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.017793893814086914s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.03449678421020508s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 41 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 47 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_jobs = {task_name:[] for task_name in tasks}\n",
    "breakout=False\n",
    "for subject in needed_subids:\n",
    "    sub_task_dir = task_data_dir / subject\n",
    "    for task_name in tasks:\n",
    "        for runnum in [0,1,2]:\n",
    "            if runnum == 2 and task_name != 'rdm':\n",
    "                continue\n",
    "            zipped_path = sub_task_dir / f'{task_name}_{runnum}.zip'\n",
    "            if zipped_path.exists():\n",
    "                file_date = datetime.fromtimestamp(zipped_path.stat().st_mtime)\n",
    "                if file_date < start_time:\n",
    "                    continue\n",
    "                loddf = delayed(load_task)(zipped_path, task_name, subject, runnum)\n",
    "                task_jobs[task_name].append(loddf)\n",
    "            else:\n",
    "                print(zipped_path)\n",
    "                continue\n",
    "\n",
    "addl_task_dat = {task_name:[] for task_name in tasks}\n",
    "for task_name in tasks:\n",
    "    addl_task_dat[task_name] = pl.concat(Parallel(n_jobs=8, verbose=10)(task_jobs[task_name]), how='diagonal_relaxed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff1000",
   "metadata": {},
   "source": [
    "## process exclusion boxcox outlier exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60865bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for task_name in tasks:\n",
    "    low_limit, high_limit = limits[task_name]\n",
    "    tdf = addl_task_dat[task_name]\n",
    "    if task_name == 'bart':\n",
    "        # For bart, just drop trials with weird out of range RTs\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds')\n",
    "        ).with_columns(\n",
    "            pl.col('rt_inbounds').alias('keep')\n",
    "        )\n",
    "    else:\n",
    "        # For non-bart, mark nonresponse trials, don't inlcude them in the initial bc_mask\n",
    "        # also don't include trials with weird out of bounds rts in the initial bc_mask\n",
    "        # Keep non-response trials along with trials passing box-cox filtering\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds'),\n",
    "            pl.when(pl.col('rt').is_null()).then(True).otherwise(False).alias('nonresponse'),\n",
    "        ).with_columns(\n",
    "            pl.when((~pl.col('rt_inbounds')) | pl.col('nonresponse')).then(False).otherwise(True).alias('bc_mask')\n",
    "        ).with_columns(\n",
    "            bc_mask=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: boxcoxmask(x), return_dtype=pl.Boolean).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_rt=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: nanboxcox(x), return_dtype=pl.Float64).fill_nan(None).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_z_rt=pl.when(pl.col('bc_mask')).then((pl.col('rt') - pl.col('rt').mean()) / pl.col('rt').std()).over(pl.col('sub_id'))\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col('nonresponse') | pl.col('bc_mask')).then(True).otherwise(False).alias('keep')\n",
    "        )\n",
    "    addl_task_dat[task_name] = tdff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e538de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch:\n",
    "    for task_name in tasks: \n",
    "        tdf = task_dat[task_name]\n",
    "        atdf = addl_task_dat[task_name]\n",
    "        ctdf = pl.concat([tdf, atdf], how='diagonal_relaxed')\n",
    "        task_dat[task_name] = ctdf\n",
    "else:\n",
    "    task_dat = {task_name:[] for task_name in tasks}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = addl_task_dat[task_name]\n",
    "\n",
    "# identify subjects that have the expected number of blocks per task\n",
    "complete = []\n",
    "for task_name in tasks:\n",
    "    tdf = task_dat[task_name]\n",
    "    expected_n = 2\n",
    "    if task_name== 'rdm':\n",
    "        expected_n = 3\n",
    "    tmp = (tdf.group_by('sub_id').n_unique()\n",
    "        .select(['sub_id', 'zrn']).with_columns(\n",
    "            (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "            ).select(['sub_id', f'has_all_{task_name}']))\n",
    "    complete.append(tmp)\n",
    "complete = pl.concat(complete, how='align').with_columns(\n",
    "    has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b70bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that exclusion criteria are correct\n",
    "for task_name in tasks:\n",
    "    if task_name != 'bart':\n",
    "        tdff = task_dat[task_name]\n",
    "        # check that we're correctly picking trials to include\n",
    "        assert (tdff.filter(pl.col('bc_mask') | pl.col('nonresponse'))).select('keep').to_series().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc063ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in tasks:\n",
    "    tdff = task_dat[task_name]\n",
    "    tdff.write_parquet(data_dir/f'{task_name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d50eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process subject level exclusion\n",
    "# subjects are excluded if:\n",
    "# 1) they have below chance performance\n",
    "# 2) > 5 or 10 % of trials are non-response or exluded by box-cox\n",
    "# bc_mask is true if the trial is within RT response bounds, has a response, and passed box-cox outlier exclusion\n",
    "tkeeps = []\n",
    "for task_name in tasks:\n",
    "    if task_name == 'cab':\n",
    "        task_dat[task_name] = task_dat[task_name].with_columns(\n",
    "            (pl.col('resp_acc') == True).alias('correct')\n",
    "        )\n",
    "    tdff = task_dat[task_name]\n",
    "    \n",
    "    if task_name == 'rdm':\n",
    "        tkeep = tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        tdff = tdff.with_columns(coh_dif=(pl.col('left_coherence') - pl.col('right_coherence')).abs())\n",
    "        tcorr = tdff.filter(pl.col('coh_dif') > 0).group_by(pl.col('sub_id')).sum().select(['sub_id','correct'])\n",
    "        tkeep = tkeep.join(tcorr, how='left', on='sub_id')\n",
    "    elif task_name == 'bart':\n",
    "        tkeep = tdff.group_by(['sub_id', 'zrn', 'balloon_id', 'date']).first().with_columns(\n",
    "            correct=pl.col('key_pressed') == pl.col('pump_button')\n",
    "        ).group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        ).with_columns(\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}')\n",
    "        ).with_columns(\n",
    "            pl.col(f'corr_ok_{task_name}').alias(f'good_{task_name}')\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good_{task_name}')).alias(f'bad_{task_name}')\n",
    "        ).rename({'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "    else:\n",
    "        tkeep =  tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        \n",
    "    if task_name != 'bart':\n",
    "        tkeep = tkeep.with_columns(\n",
    "            (pl.col('bc_mask') >= rt05_threshes[task_name]).alias(f'resp05_ok_{task_name}'),\n",
    "            (pl.col('bc_mask') >= rt10_threshes[task_name]).alias(f'resp10_ok_{task_name}'),\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (pl.col(f'resp05_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good05_{task_name}'),\n",
    "            (pl.col(f'resp10_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good10_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good05_{task_name}')).alias(f'bad05_{task_name}'),\n",
    "            (~pl.col(f'good10_{task_name}')).alias(f'bad10_{task_name}')\n",
    "        ).rename({\n",
    "            'bc_mask':f'n_good_resps_{task_name}', 'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "\n",
    "    tkeeps.append(tkeep)\n",
    "\n",
    "tkeep = pl.concat(tkeeps, how=\"align\").with_columns(\n",
    "    good05=(pl.col('good05_flkr') & pl.col('good_bart') & pl.col('good05_rdm') & pl.col('good05_cab')),\n",
    "    good10=(pl.col('good10_flkr') & pl.col('good_bart') & pl.col('good10_rdm') & pl.col('good10_cab')),\n",
    ").with_columns(\n",
    "    bad05=~pl.col('good05'),\n",
    "    bad10=~pl.col('good10')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8fe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep = tkeep.join(complete.select(['sub_id', 'has_all']), on='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede8c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a data quality CSV for participant filtering\n",
    "tkeep.write_csv(out_dir / 'data_quality.csv')\n",
    "# write out data for all subjects\n",
    "for task_name in tasks:\n",
    "    tdf = task_dat[task_name]\n",
    "    subjects = tdf.select('sub_id').unique().to_numpy().flatten()\n",
    "\n",
    "    for sub_id in subjects:\n",
    "        sdf = tdf.filter(pl.col('sub_id') == sub_id)\n",
    "        sdf.write_csv(out_dir / f'{task_name}-{sub_id}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b10bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogmood-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
