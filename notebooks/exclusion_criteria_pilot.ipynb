{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b40583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x124e556a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from cogmood_analysis.load import load_task, boxcoxmask, nanboxcox, load_survey, proc_survey\n",
    "import cogmood_analysis.survey_helpers as sh\n",
    "from scipy.stats import boxcox\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import tempfile\n",
    "from zipfile import ZipFile\n",
    "from cogmood_analysis import log\n",
    "import pickle\n",
    "pl.Config(tbl_rows=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced7557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/nielsond/code/cogmood/data/20250611_pilot/good_task')\n",
    "out_dir = Path('/Users/nielsond/code/cogmood/data/20250611_pilot/to_model')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "task_data_dir = data_dir\n",
    "start_time = pl.Series(['2025-06-09 00:00:00']).str.to_datetime()[0]\n",
    "tasks = ['flkr', 'cab', 'rdm', 'bart']\n",
    "bad_dirs = ['.DS_Store']\n",
    "from_scratch = True\n",
    "\n",
    "#timing limits\n",
    "limits = {\n",
    "    'cab': (0.2, 2.5),\n",
    "    'flkr': (0.1, 3),\n",
    "    'rdm': (0.1, 3),\n",
    "    'bart': (0, 100)\n",
    "}\n",
    "\n",
    "# chance threshold\n",
    "# have to press pump on first trial of at least 24 of 36 balloons \n",
    "# for p = 0.032 < 0.05 responses are not at random\n",
    "# (23 is 0.066)\n",
    "bart_thresh = 24\n",
    "# cab\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "cab_thresh = 57\n",
    "# cab_rt_thresh05 = 4.8\n",
    "# cab_rt_thresh10 = 9.6\n",
    "#rdm\n",
    "# correct response on 105 out of 186 nonrandom trials\n",
    "# for p = 0.045 < 0.05 responses are not at random\n",
    "# (104 is 0.062)\n",
    "rdm_thresh = 105\n",
    "# rdm_rt_thresh05 = 222 * 0.05\n",
    "# rdm_rt_thresh10 = 222 * 0.1\n",
    "# flkr\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "flkr_thresh = 57\n",
    "# flkr_rt_thresh05 = 4.8\n",
    "# flkr_rt_thresh10 = 9.6\n",
    "\n",
    "corr_threshes = {\n",
    "    'bart': bart_thresh,\n",
    "    'cab': cab_thresh,\n",
    "    'rdm': rdm_thresh,\n",
    "    'flkr': flkr_thresh\n",
    "}\n",
    "# invert thresholds to get mimimum number passing\n",
    "rt05_threshes = {\n",
    "    'cab': 96 * 0.95,\n",
    "    'rdm': 222 * 0.95,\n",
    "    'flkr': 96 * 0.95\n",
    "}\n",
    "\n",
    "rt10_threshes = {\n",
    "    'cab': 96 * 0.9,\n",
    "    'rdm': 222 * 0.9,\n",
    "    'flkr': 96 * 0.9\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427fb52",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not from_scratch:\n",
    "    task_dat = {}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = pl.read_parquet(data_dir/f'{task_name}.parquet')\n",
    "\n",
    "    complete = []\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        expected_n = 2\n",
    "        if task_name== 'rdm':\n",
    "            expected_n = 3\n",
    "        tmp = (tdf.group_by('sub_id').n_unique()\n",
    "            .select(['sub_id', 'zrn']).with_columns(\n",
    "                (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "                ).select(['sub_id', f'has_all_{task_name}']))\n",
    "        complete.append(tmp)\n",
    "    complete = pl.concat(complete, how='align').with_columns(\n",
    "        has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    "    )\n",
    "\n",
    "    complete_subs = complete.filter('has_all').get_column('sub_id').to_list()\n",
    "else:\n",
    "    complete_subs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7343a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subids = sorted([dd.parts[-1] for dd in (data_dir).glob('*') if (dd.parts[-1] not in bad_dirs) and ('parquet' not in dd.parts[-1])])\n",
    "needed_subids = [sid for sid in all_subids if sid not in complete_subs]\n",
    "# go ahead and just drop all the needed_subids\n",
    "if not from_scratch:\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        task_dat[task_name] = tdf.filter(~pl.col('sub_id').is_in(needed_subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c528b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 25 out of 56 | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.18306021607825182s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 47 out of 56 | elapsed:    2.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 53 out of 56 | elapsed:    2.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.009424924850463867s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.03826308250427246s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 53 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.008435964584350586s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 84 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.03444194793701172s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 84 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 60 out of 84 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 84 out of 84 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.013975858688354492s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done  2 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  9 out of 56 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 16 out of 56 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.05870199203491211s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done 34 out of 56 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 41 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 47 out of 56 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 53 out of 56 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 56 out of 56 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_jobs = {task_name:[] for task_name in tasks}\n",
    "breakout=False\n",
    "for subject in needed_subids:\n",
    "    sub_task_dir = task_data_dir / subject\n",
    "    for task_name in tasks:\n",
    "        for runnum in [0,1,2]:\n",
    "            if runnum == 2 and task_name != 'rdm':\n",
    "                continue\n",
    "            zipped_path = sub_task_dir / f'{task_name}_{runnum}.zip'\n",
    "            if zipped_path.exists():\n",
    "                file_date = datetime.fromtimestamp(zipped_path.stat().st_mtime)\n",
    "                if file_date < start_time:\n",
    "                    continue\n",
    "                loddf = delayed(load_task)(zipped_path, task_name, subject, runnum)\n",
    "                task_jobs[task_name].append(loddf)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "addl_task_dat = {task_name:[] for task_name in tasks}\n",
    "for task_name in tasks:\n",
    "    addl_task_dat[task_name] = pl.concat(Parallel(n_jobs=8, verbose=10)(task_jobs[task_name]), how='diagonal_relaxed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff1000",
   "metadata": {},
   "source": [
    "## process exclusion boxcox outlier exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60865bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for task_name in tasks:\n",
    "    low_limit, high_limit = limits[task_name]\n",
    "    tdf = addl_task_dat[task_name]\n",
    "    if task_name == 'bart':\n",
    "        # For bart, just drop trials with weird out of range RTs\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds')\n",
    "        ).with_columns(\n",
    "            pl.col('rt_inbounds').alias('keep')\n",
    "        )\n",
    "    else:\n",
    "        # For non-bart, mark nonresponse trials, don't inlcude them in the initial bc_mask\n",
    "        # also don't include trials with weird out of bounds rts in the initial bc_mask\n",
    "        # Keep non-response trials along with trials passing box-cox filtering\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds'),\n",
    "            pl.when(pl.col('rt').is_null()).then(True).otherwise(False).alias('nonresponse'),\n",
    "        ).with_columns(\n",
    "            pl.when((~pl.col('rt_inbounds')) | pl.col('nonresponse')).then(False).otherwise(True).alias('bc_mask')\n",
    "        ).with_columns(\n",
    "            pl.col('bc_mask').alias('bc_mask25')\n",
    "        ).with_columns(\n",
    "            bc_mask=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: boxcoxmask(x), return_dtype=pl.Boolean).over(pl.col('sub_id')),\n",
    "            bc_mask25=pl.when(pl.col('bc_mask25')).then(pl.col('rt')).map_batches(lambda x: boxcoxmask(x, thresh=2.5), return_dtype=pl.Boolean).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_rt=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: nanboxcox(x), return_dtype=pl.Float64).fill_nan(None).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_z_rt=pl.when(pl.col('bc_mask')).then((pl.col('rt') - pl.col('rt').mean()) / pl.col('rt').std()).over(pl.col('sub_id'))\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col('nonresponse') | pl.col('bc_mask')).then(True).otherwise(False).alias('keep')\n",
    "        )\n",
    "    addl_task_dat[task_name] = tdff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e538de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch:\n",
    "    for task_name in tasks: \n",
    "        tdf = task_dat[task_name]\n",
    "        atdf = addl_task_dat[task_name]\n",
    "        ctdf = pl.concat([tdf, atdf], how='diagonal_relaxed')\n",
    "        task_dat[task_name] = ctdf\n",
    "else:\n",
    "    task_dat = {task_name:[] for task_name in tasks}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = addl_task_dat[task_name]\n",
    "\n",
    "# identify subjects that have the expected number of blocks per task\n",
    "complete = []\n",
    "for task_name in tasks:\n",
    "    tdf = task_dat[task_name]\n",
    "    expected_n = 2\n",
    "    if task_name== 'rdm':\n",
    "        expected_n = 3\n",
    "    tmp = (tdf.group_by('sub_id').n_unique()\n",
    "        .select(['sub_id', 'zrn']).with_columns(\n",
    "            (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "            ).select(['sub_id', f'has_all_{task_name}']))\n",
    "    complete.append(tmp)\n",
    "complete = pl.concat(complete, how='align').with_columns(\n",
    "    has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b70bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that exclusion criteria are correct\n",
    "for task_name in tasks:\n",
    "    if task_name != 'bart':\n",
    "        tdff = task_dat[task_name]\n",
    "        # check that we're correctly picking trials to include\n",
    "        assert (tdff.filter(pl.col('bc_mask') | pl.col('nonresponse'))).select('keep').to_series().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc063ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in tasks:\n",
    "    old_task_dat = pl.read_parquet(data_dir/f'{task_name}.parquet')\n",
    "    tdff = task_dat[task_name]\n",
    "    if tdff.equals(old_task_dat):\n",
    "        continue\n",
    "    else:\n",
    "        old_task_dat.write_parquet(data_dir/f'{task_name}_old.parquet')\n",
    "        tdff.write_parquet(data_dir/f'{task_name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d50eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process subject level exclusion\n",
    "# subjects are excluded if:\n",
    "# 1) they have below chance performance\n",
    "# 2) > 5 or 10 % of trials are non-response or exluded by box-cox\n",
    "# bc_mask is true if the trial is within RT response bounds, has a response, and passed box-cox outlier exclusion\n",
    "tkeeps = []\n",
    "for task_name in tasks:\n",
    "    if task_name == 'cab':\n",
    "        task_dat[task_name] = task_dat[task_name].with_columns(\n",
    "            (pl.col('resp_acc') == True).alias('correct')\n",
    "        )\n",
    "    tdff = task_dat[task_name]\n",
    "    \n",
    "    if task_name == 'rdm':\n",
    "        tkeep = tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.sum('bc_mask25').alias('bc_mask25'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        tdff = tdff.with_columns(coh_dif=(pl.col('left_coherence') - pl.col('right_coherence')).abs())\n",
    "        tcorr = tdff.filter(pl.col('coh_dif') > 0).group_by(pl.col('sub_id')).sum().select(['sub_id','correct'])\n",
    "        tkeep = tkeep.join(tcorr, how='left', on='sub_id')\n",
    "    elif task_name == 'bart':\n",
    "        tkeep = tdff.group_by(['sub_id', 'zrn', 'balloon_id', 'date']).first().with_columns(\n",
    "            correct=pl.col('key_pressed') == pl.col('pump_button')\n",
    "        ).group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        ).with_columns(\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}')\n",
    "        ).with_columns(\n",
    "            pl.col(f'corr_ok_{task_name}').alias(f'good_{task_name}')\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good_{task_name}')).alias(f'bad_{task_name}')\n",
    "        ).rename({'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "    else:\n",
    "        tkeep =  tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.sum('bc_mask25').alias('bc_mask25'),\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        \n",
    "    if task_name != 'bart':\n",
    "        tkeep = tkeep.with_columns(\n",
    "            (pl.col('bc_mask') >= rt05_threshes[task_name]).alias(f'resp05_ok_{task_name}'),\n",
    "            (pl.col('bc_mask') >= rt10_threshes[task_name]).alias(f'resp10_ok_{task_name}'),\n",
    "            (pl.col('bc_mask25') >= rt05_threshes[task_name]).alias(f'bc25_resp05_ok_{task_name}'),\n",
    "            (pl.col('bc_mask25') >= rt10_threshes[task_name]).alias(f'bc25_resp10_ok_{task_name}'),\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (pl.col(f'resp05_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good05_{task_name}'),\n",
    "            (pl.col(f'resp10_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good10_{task_name}'),\n",
    "            (pl.col(f'bc25_resp05_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'bc25_good05_{task_name}'),\n",
    "            (pl.col(f'bc25_resp10_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'bc25_good10_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good05_{task_name}')).alias(f'bad05_{task_name}'),\n",
    "            (~pl.col(f'good10_{task_name}')).alias(f'bad10_{task_name}'),\n",
    "            (~pl.col(f'bc25_good05_{task_name}')).alias(f'bc25_bad05_{task_name}'),\n",
    "            (~pl.col(f'bc25_good10_{task_name}')).alias(f'bc25_bad10_{task_name}')\n",
    "        ).rename({\n",
    "            'bc_mask':f'n_good_resps_{task_name}', 'bc_mask25':f'bc25_n_good_resps_{task_name}', 'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "\n",
    "    tkeeps.append(tkeep)\n",
    "\n",
    "tkeep = pl.concat(tkeeps, how=\"align\").with_columns(\n",
    "    good05=(pl.col('good05_flkr') & pl.col('good_bart') & pl.col('good05_rdm') & pl.col('good05_cab')),\n",
    "    good10=(pl.col('good10_flkr') & pl.col('good_bart') & pl.col('good10_rdm') & pl.col('good10_cab')),\n",
    "    bc25_good05=(pl.col('bc25_good05_flkr') & pl.col('good_bart') & pl.col('bc25_good05_rdm') & pl.col('bc25_good05_cab')),\n",
    "    bc25_good10=(pl.col('bc25_good10_flkr') & pl.col('good_bart') & pl.col('bc25_good10_rdm') & pl.col('bc25_good10_cab')),\n",
    ").with_columns(\n",
    "    bad05=~pl.col('good05'),\n",
    "    bad10=~pl.col('good10')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8fe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep = tkeep.join(complete.select(['sub_id', 'has_all']), on='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6783462",
   "metadata": {},
   "outputs": [],
   "source": [
    "cab_misfits = [\n",
    "    'd4hsof73ftqmz1sbm3vc82f6',\n",
    "    '60pixcark57tgonq4abwctvs',\n",
    "    'sz1p1qr5v5saov60ia90oqlh',\n",
    "]\n",
    "rdm_misfits = [\n",
    "    'h3q7g3g6za07rl9qnhd87hoq',\n",
    "    'ycbg09io1hcmzyiosg50hgl8',\n",
    "    '1ts935dhccck7dgtssvxv9nd',\n",
    "    'reqevxyh9eqa3jyc8wvucdi2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ae426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (3, 5)\n",
       " ┌─────────────────────┬──────────────────┬────────────────────┬───────────────┬────────────────────┐\n",
       " │ sub_id              ┆ n_good_resps_cab ┆ bc25_n_good_resps_ ┆ resp10_ok_cab ┆ bc25_resp10_ok_cab │\n",
       " │ ---                 ┆ ---              ┆ cab                ┆ ---           ┆ ---                │\n",
       " │ str                 ┆ u32              ┆ ---                ┆ bool          ┆ bool               │\n",
       " │                     ┆                  ┆ u32                ┆               ┆                    │\n",
       " ╞═════════════════════╪══════════════════╪════════════════════╪═══════════════╪════════════════════╡\n",
       " │ 60pixcark57tgonq4ab ┆ 95               ┆ 94                 ┆ true          ┆ true               │\n",
       " │ wctvs               ┆                  ┆                    ┆               ┆                    │\n",
       " │ d4hsof73ftqmz1sbm3v ┆ 93               ┆ 92                 ┆ true          ┆ true               │\n",
       " │ c82f6               ┆                  ┆                    ┆               ┆                    │\n",
       " │ sz1p1qr5v5saov60ia9 ┆ 94               ┆ 93                 ┆ true          ┆ true               │\n",
       " │ 0oqlh               ┆                  ┆                    ┆               ┆                    │\n",
       " └─────────────────────┴──────────────────┴────────────────────┴───────────────┴────────────────────┘,\n",
       " shape: (4, 5)\n",
       " ┌─────────────────────┬──────────────────┬────────────────────┬───────────────┬────────────────────┐\n",
       " │ sub_id              ┆ n_good_resps_rdm ┆ bc25_n_good_resps_ ┆ resp10_ok_rdm ┆ bc25_resp10_ok_rdm │\n",
       " │ ---                 ┆ ---              ┆ rdm                ┆ ---           ┆ ---                │\n",
       " │ str                 ┆ u32              ┆ ---                ┆ bool          ┆ bool               │\n",
       " │                     ┆                  ┆ u32                ┆               ┆                    │\n",
       " ╞═════════════════════╪══════════════════╪════════════════════╪═══════════════╪════════════════════╡\n",
       " │ 1ts935dhccck7dgtssv ┆ 214              ┆ 202                ┆ true          ┆ true               │\n",
       " │ xv9nd               ┆                  ┆                    ┆               ┆                    │\n",
       " │ h3q7g3g6za07rl9qnhd ┆ 218              ┆ 212                ┆ true          ┆ true               │\n",
       " │ 87hoq               ┆                  ┆                    ┆               ┆                    │\n",
       " │ reqevxyh9eqa3jyc8wv ┆ 220              ┆ 218                ┆ true          ┆ true               │\n",
       " │ ucdi2               ┆                  ┆                    ┆               ┆                    │\n",
       " │ ycbg09io1hcmzyiosg5 ┆ 220              ┆ 216                ┆ true          ┆ true               │\n",
       " │ 0hgl8               ┆                  ┆                    ┆               ┆                    │\n",
       " └─────────────────────┴──────────────────┴────────────────────┴───────────────┴────────────────────┘)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkeep.filter(pl.col('sub_id').is_in(cab_misfits)).select(['sub_id', 'n_good_resps_cab', 'bc25_n_good_resps_cab', 'resp10_ok_cab', 'bc25_resp10_ok_cab']), tkeep.filter(pl.col('sub_id').is_in(rdm_misfits)).select(['sub_id', 'n_good_resps_rdm', 'bc25_n_good_resps_rdm', 'resp10_ok_rdm', 'bc25_resp10_ok_rdm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede8c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a data quality CSV for participant filtering\n",
    "tkeep.write_csv(out_dir / 'data_quality.csv')\n",
    "# write out data for all subjects\n",
    "for task_name in tasks:\n",
    "    tdf = task_dat[task_name]\n",
    "    subjects = tdf.select('sub_id').unique().to_numpy().flatten()\n",
    "\n",
    "    for sub_id in subjects:\n",
    "        sdf = tdf.filter(pl.col('sub_id') == sub_id)\n",
    "        sdf.write_csv(out_dir / f'{task_name}-{sub_id}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15f4d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 64)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sub_id</th><th>n_good_resps_flkr</th><th>bc25_n_good_resps_flkr</th><th>n_correct_flkr</th><th>date_flkr</th><th>resp05_ok_flkr</th><th>resp10_ok_flkr</th><th>bc25_resp05_ok_flkr</th><th>bc25_resp10_ok_flkr</th><th>corr_ok_flkr</th><th>good05_flkr</th><th>good10_flkr</th><th>bc25_good05_flkr</th><th>bc25_good10_flkr</th><th>bad05_flkr</th><th>bad10_flkr</th><th>bc25_bad05_flkr</th><th>bc25_bad10_flkr</th><th>n_good_resps_cab</th><th>bc25_n_good_resps_cab</th><th>n_correct_cab</th><th>date_cab</th><th>resp05_ok_cab</th><th>resp10_ok_cab</th><th>bc25_resp05_ok_cab</th><th>bc25_resp10_ok_cab</th><th>corr_ok_cab</th><th>good05_cab</th><th>good10_cab</th><th>bc25_good05_cab</th><th>bc25_good10_cab</th><th>bad05_cab</th><th>bad10_cab</th><th>bc25_bad05_cab</th><th>bc25_bad10_cab</th><th>n_good_resps_rdm</th><th>bc25_n_good_resps_rdm</th><th>date_rdm</th><th>n_correct_rdm</th><th>resp05_ok_rdm</th><th>resp10_ok_rdm</th><th>bc25_resp05_ok_rdm</th><th>bc25_resp10_ok_rdm</th><th>corr_ok_rdm</th><th>good05_rdm</th><th>good10_rdm</th><th>bc25_good05_rdm</th><th>bc25_good10_rdm</th><th>bad05_rdm</th><th>bad10_rdm</th><th>bc25_bad05_rdm</th><th>bc25_bad10_rdm</th><th>n_correct_bart</th><th>date_bart</th><th>corr_ok_bart</th><th>good_bart</th><th>bad_bart</th><th>good05</th><th>good10</th><th>bc25_good05</th><th>bc25_good10</th><th>bad05</th><th>bad10</th><th>has_all</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>null</td><td>2652</td><td>2624</td><td>2494</td><td>null</td><td>26</td><td>27</td><td>24</td><td>27</td><td>26</td><td>25</td><td>25</td><td>23</td><td>25</td><td>3</td><td>3</td><td>5</td><td>3</td><td>2602</td><td>2569</td><td>2077</td><td>null</td><td>24</td><td>25</td><td>21</td><td>25</td><td>28</td><td>24</td><td>25</td><td>21</td><td>25</td><td>4</td><td>3</td><td>7</td><td>3</td><td>6105</td><td>6034</td><td>null</td><td>4066</td><td>25</td><td>28</td><td>23</td><td>28</td><td>25</td><td>22</td><td>25</td><td>21</td><td>25</td><td>6</td><td>3</td><td>7</td><td>3</td><td>992</td><td>null</td><td>28</td><td>28</td><td>0</td><td>19</td><td>22</td><td>16</td><td>22</td><td>9</td><td>6</td><td>28</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 64)\n",
       "┌────────┬───────────────┬──────────────┬──────────────┬───┬─────────────┬───────┬───────┬─────────┐\n",
       "│ sub_id ┆ n_good_resps_ ┆ bc25_n_good_ ┆ n_correct_fl ┆ … ┆ bc25_good10 ┆ bad05 ┆ bad10 ┆ has_all │\n",
       "│ ---    ┆ flkr          ┆ resps_flkr   ┆ kr           ┆   ┆ ---         ┆ ---   ┆ ---   ┆ ---     │\n",
       "│ str    ┆ ---           ┆ ---          ┆ ---          ┆   ┆ u32         ┆ u32   ┆ u32   ┆ u32     │\n",
       "│        ┆ u32           ┆ u32          ┆ u32          ┆   ┆             ┆       ┆       ┆         │\n",
       "╞════════╪═══════════════╪══════════════╪══════════════╪═══╪═════════════╪═══════╪═══════╪═════════╡\n",
       "│ null   ┆ 2652          ┆ 2624         ┆ 2494         ┆ … ┆ 22          ┆ 9     ┆ 6     ┆ 28      │\n",
       "└────────┴───────────────┴──────────────┴──────────────┴───┴─────────────┴───────┴───────┴─────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkeep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "301b10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 64)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sub_id</th><th>n_good_resps_flkr</th><th>bc25_n_good_resps_flkr</th><th>n_correct_flkr</th><th>date_flkr</th><th>resp05_ok_flkr</th><th>resp10_ok_flkr</th><th>bc25_resp05_ok_flkr</th><th>bc25_resp10_ok_flkr</th><th>corr_ok_flkr</th><th>good05_flkr</th><th>good10_flkr</th><th>bc25_good05_flkr</th><th>bc25_good10_flkr</th><th>bad05_flkr</th><th>bad10_flkr</th><th>bc25_bad05_flkr</th><th>bc25_bad10_flkr</th><th>n_good_resps_cab</th><th>bc25_n_good_resps_cab</th><th>n_correct_cab</th><th>date_cab</th><th>resp05_ok_cab</th><th>resp10_ok_cab</th><th>bc25_resp05_ok_cab</th><th>bc25_resp10_ok_cab</th><th>corr_ok_cab</th><th>good05_cab</th><th>good10_cab</th><th>bc25_good05_cab</th><th>bc25_good10_cab</th><th>bad05_cab</th><th>bad10_cab</th><th>bc25_bad05_cab</th><th>bc25_bad10_cab</th><th>n_good_resps_rdm</th><th>bc25_n_good_resps_rdm</th><th>date_rdm</th><th>n_correct_rdm</th><th>resp05_ok_rdm</th><th>resp10_ok_rdm</th><th>bc25_resp05_ok_rdm</th><th>bc25_resp10_ok_rdm</th><th>corr_ok_rdm</th><th>good05_rdm</th><th>good10_rdm</th><th>bc25_good05_rdm</th><th>bc25_good10_rdm</th><th>bad05_rdm</th><th>bad10_rdm</th><th>bc25_bad05_rdm</th><th>bc25_bad10_rdm</th><th>n_correct_bart</th><th>date_bart</th><th>corr_ok_bart</th><th>good_bart</th><th>bad_bart</th><th>good05</th><th>good10</th><th>bc25_good05</th><th>bc25_good10</th><th>bad05</th><th>bad10</th><th>has_all</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>datetime[μs]</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>null</td><td>2652</td><td>2624</td><td>2494</td><td>null</td><td>26</td><td>27</td><td>24</td><td>27</td><td>26</td><td>25</td><td>25</td><td>23</td><td>25</td><td>3</td><td>3</td><td>5</td><td>3</td><td>2602</td><td>2569</td><td>2077</td><td>null</td><td>24</td><td>25</td><td>21</td><td>25</td><td>28</td><td>24</td><td>25</td><td>21</td><td>25</td><td>4</td><td>3</td><td>7</td><td>3</td><td>6105</td><td>6034</td><td>null</td><td>4066</td><td>25</td><td>28</td><td>23</td><td>28</td><td>25</td><td>22</td><td>25</td><td>21</td><td>25</td><td>6</td><td>3</td><td>7</td><td>3</td><td>992</td><td>null</td><td>28</td><td>28</td><td>0</td><td>19</td><td>22</td><td>16</td><td>22</td><td>9</td><td>6</td><td>28</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 64)\n",
       "┌────────┬───────────────┬──────────────┬──────────────┬───┬─────────────┬───────┬───────┬─────────┐\n",
       "│ sub_id ┆ n_good_resps_ ┆ bc25_n_good_ ┆ n_correct_fl ┆ … ┆ bc25_good10 ┆ bad05 ┆ bad10 ┆ has_all │\n",
       "│ ---    ┆ flkr          ┆ resps_flkr   ┆ kr           ┆   ┆ ---         ┆ ---   ┆ ---   ┆ ---     │\n",
       "│ str    ┆ ---           ┆ ---          ┆ ---          ┆   ┆ u32         ┆ u32   ┆ u32   ┆ u32     │\n",
       "│        ┆ u32           ┆ u32          ┆ u32          ┆   ┆             ┆       ┆       ┆         │\n",
       "╞════════╪═══════════════╪══════════════╪══════════════╪═══╪═════════════╪═══════╪═══════╪═════════╡\n",
       "│ null   ┆ 2652          ┆ 2624         ┆ 2494         ┆ … ┆ 22          ┆ 9     ┆ 6     ┆ 28      │\n",
       "└────────┴───────────────┴──────────────┴──────────────┴───┴─────────────┴───────┴───────┴─────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkeep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf09f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkeep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30f2a0",
   "metadata": {},
   "source": [
    "# Extract bart pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff867adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_bart_pickles = []\n",
    "for subject in needed_subids:\n",
    "    sub_task_dir = task_data_dir / subject\n",
    "    for task_name in ['bart']:\n",
    "        for runnum in [0,1,2]:\n",
    "            if runnum == 2 and task_name != 'rdm':\n",
    "                continue\n",
    "            zipped_path = sub_task_dir / f'{task_name}_{runnum}.zip'\n",
    "            try:\n",
    "                with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                    bart_pickle = Path(ZipFile(zipped_path).extract(f\"obart_pickles/bags_session_{runnum}.p\", path=tmpdir))\n",
    "                    bart_pd = pickle.loads(bart_pickle.read_bytes())\n",
    "            except KeyError:\n",
    "                missing_bart_pickles.append(subject)\n",
    "                continue\n",
    "            bart_pickle_dir = out_dir / f\"bart-{subject}_pickles\"\n",
    "            bart_pickle_dir.mkdir(exist_ok=True)\n",
    "            bart_pickle_file = bart_pickle_dir / f\"bags_session_{runnum}.pickle\"\n",
    "            bart_pickle_file.write_bytes(pickle.dumps(bart_pd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a429f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogmood-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
