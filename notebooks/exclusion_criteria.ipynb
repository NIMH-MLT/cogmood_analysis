{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b40583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from cogmood_analysis.load import load_task, boxcoxmask, nanboxcox, load_survey, proc_survey\n",
    "import cogmood_analysis.survey_helpers as sh\n",
    "from scipy.stats import boxcox\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "import json\n",
    "pl.Config(tbl_rows=300)\n",
    "pl.Config(tbl_cols=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde5b6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/')\n",
    "survey_dir = data_dir / 'survey'\n",
    "complete_dir = survey_dir / 'complete'\n",
    "task_data_dir = data_dir / 'task/upload'\n",
    "task_db_dir = data_dir / 'task/db'\n",
    "task_tomodel_dir = data_dir / 'task/to_model'\n",
    "task_tomodel_dir.mkdir(exist_ok=True)\n",
    "start_time = pl.Series(['2025-07-11 00:00:00']).str.to_datetime()[0]\n",
    "tasks = ['flkr', 'cab', 'rdm', 'bart']\n",
    "bad_dirs = []\n",
    "from_scratch = False\n",
    "\n",
    "#timing limits\n",
    "default_high_limit = 2\n",
    "default_low_limit = 0.350\n",
    "limits = {\n",
    "    'cab': (0.2, 2.5),\n",
    "    'flkr': (0.1, 3),\n",
    "    'rdm': (0.1, 3),\n",
    "    'bart': (0, 100)\n",
    "}\n",
    "\n",
    "# chance threshold\n",
    "# have to press pump on first trial of at least 24 of 36 balloons \n",
    "# for p = 0.032 < 0.05 responses are not at random\n",
    "# (23 is 0.066)\n",
    "bart_thresh = 24\n",
    "# cab\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "cab_thresh = 57\n",
    "cab_rt_thresh05 = 4.8\n",
    "cab_rt_thresh10 = 9.6\n",
    "#rdm\n",
    "# correct response on 105 out of 186 nonrandom trials\n",
    "# for p = 0.045 < 0.05 responses are not at random\n",
    "# (104 is 0.062)\n",
    "rdm_thresh = 105\n",
    "rdm_rt_thresh05 = 222 * 0.05\n",
    "rdm_rt_thresh10 = 222 * 0.1\n",
    "# flkr\n",
    "# correct response on 57 out of 96 trials\n",
    "# for p = 0.041 < 0.05 responses are not at random\n",
    "# (56 is 0.0625)\n",
    "flkr_thresh = 57\n",
    "flkr_rt_thresh05 = 4.8\n",
    "flkr_rt_thresh10 = 9.6\n",
    "\n",
    "corr_threshes = {\n",
    "    'bart': 24,\n",
    "    'cab': 57,\n",
    "    'rdm': 105,\n",
    "    'flkr': 57\n",
    "}\n",
    "# invert thresholds to get mimimum number passing\n",
    "rt05_threshes = {\n",
    "    'cab': 96 * 0.95,\n",
    "    'rdm': 222 * 0.95,\n",
    "    'flkr': 96 * 0.95\n",
    "}\n",
    "rt10_threshes = {\n",
    "    'cab': 96 * 0.9,\n",
    "    'rdm': 222 * 0.9,\n",
    "    'flkr': 96 * 0.9\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427fb52",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not from_scratch:\n",
    "    task_dat = {}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = pl.read_parquet(data_dir/f'{task_name}.parquet')\n",
    "\n",
    "    complete = []\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        expected_n = 2\n",
    "        if task_name== 'rdm':\n",
    "            expected_n = 3\n",
    "        tmp = (tdf.group_by('sub_id').n_unique()\n",
    "            .select(['sub_id', 'zrn']).with_columns(\n",
    "                (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "                ).select(['sub_id', f'has_all_{task_name}']))\n",
    "        complete.append(tmp)\n",
    "    complete = pl.concat(complete, how='align').with_columns(\n",
    "        has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    "    )\n",
    "\n",
    "    complete_subs = complete.filter('has_all').get_column('sub_id').to_list()\n",
    "else:\n",
    "    complete_subs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7343a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subids = sorted([dd.parts[-1] for dd in (data_dir/'task/upload').glob('*') if (dd.parts[-1] not in bad_dirs)])\n",
    "needed_subids = [sid for sid in all_subids if sid not in complete_subs]\n",
    "# go ahead and just drop all the needed_subids\n",
    "if not from_scratch:\n",
    "    for task_name in tasks:\n",
    "        tdf = task_dat[task_name]\n",
    "        task_dat[task_name] = tdf.filter(~pl.col('sub_id').is_in(needed_subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_jobs = {task_name:[] for task_name in tasks}\n",
    "breakout=False\n",
    "for subject in needed_subids:\n",
    "    sub_task_dir = task_data_dir / subject\n",
    "    for task_name in tasks:\n",
    "        for runnum in [0,1,2]:\n",
    "            if runnum == 2 and task_name != 'rdm':\n",
    "                continue\n",
    "            zipped_path = sub_task_dir / f'{task_name}_{runnum}.zip'\n",
    "            if zipped_path.exists():\n",
    "                file_date = datetime.fromtimestamp(zipped_path.stat().st_mtime)\n",
    "                if file_date < start_time:\n",
    "                    continue\n",
    "                loddf = delayed(load_task)(zipped_path, task_name, subject, runnum)\n",
    "                task_jobs[task_name].append(loddf)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "addl_task_dat = {task_name:[] for task_name in tasks}\n",
    "for task_name in tasks:\n",
    "    addl_task_dat[task_name] = pl.concat(Parallel(n_jobs=8, verbose=10)(task_jobs[task_name]), how='diagonal_relaxed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff1000",
   "metadata": {},
   "source": [
    "## process exclusion boxcox outlier exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for task_name in tasks:\n",
    "    low_limit, high_limit = limits[task_name]\n",
    "    tdf = addl_task_dat[task_name]\n",
    "    if task_name == 'bart':\n",
    "        # For bart, just drop trials with weird out of range RTs\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds')\n",
    "        ).with_columns(\n",
    "            pl.col('rt_inbounds').alias('keep')\n",
    "        )\n",
    "    else:\n",
    "        # For non-bart, mark nonresponse trials, don't inlcude them in the initial bc_mask\n",
    "        # also don't include trials with weird out of bounds rts in the initial bc_mask\n",
    "        # Keep non-response trials along with trials passing box-cox filtering\n",
    "        tdff = tdf.with_columns(\n",
    "            pl.when((pl.col('rt') > 0) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('rt_inbounds'),\n",
    "            pl.when(pl.col('rt').is_null()).then(True).otherwise(False).alias('nonresponse'),\n",
    "        ).with_columns(\n",
    "            pl.when((~pl.col('rt_inbounds')) | pl.col('nonresponse')).then(False).otherwise(True).alias('bc_mask')\n",
    "        ).with_columns(\n",
    "            bc_mask=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: boxcoxmask(x), return_dtype=pl.Boolean).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_rt=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: nanboxcox(x), return_dtype=pl.Float64).fill_nan(None).over(pl.col('sub_id')),\n",
    "        ).with_columns(\n",
    "            bc_z_rt=pl.when(pl.col('bc_mask')).then((pl.col('rt') - pl.col('rt').mean()) / pl.col('rt').std()).over(pl.col('sub_id'))\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col('nonresponse') | pl.col('bc_mask')).then(True).otherwise(False).alias('keep')\n",
    "        )\n",
    "    addl_task_dat[task_name] = tdff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch:\n",
    "    for task_name in tasks: \n",
    "        tdf = task_dat[task_name]\n",
    "        atdf = addl_task_dat[task_name]\n",
    "        ctdf = pl.concat([tdf, atdf], how='diagonal_relaxed')\n",
    "        task_dat[task_name] = ctdf\n",
    "else:\n",
    "    task_dat = {task_name:[] for task_name in tasks}\n",
    "    for task_name in tasks:\n",
    "        task_dat[task_name] = addl_task_dat[task_name]\n",
    "\n",
    "# identify subjects that have the expected number of blocks per task\n",
    "complete = []\n",
    "for task_name in tasks:\n",
    "    tdf = task_dat[task_name]\n",
    "    expected_n = 2\n",
    "    if task_name== 'rdm':\n",
    "        expected_n = 3\n",
    "    tmp = (tdf.group_by('sub_id').n_unique()\n",
    "        .select(['sub_id', 'zrn']).with_columns(\n",
    "            (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "            ).select(['sub_id', f'has_all_{task_name}']))\n",
    "    complete.append(tmp)\n",
    "complete = pl.concat(complete, how='align').with_columns(\n",
    "    has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that exclusion criteria are correct\n",
    "for task_name in tasks:\n",
    "    if task_name != 'bart':\n",
    "        tdff = task_dat[task_name]\n",
    "        # check that we're correctly picking trials to include\n",
    "        assert (tdff.filter(pl.col('bc_mask') | pl.col('nonresponse'))).select('keep').to_series().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_ids corresponding to test participants\n",
    "bad_subids = [\n",
    "    'no0z2yzyloa58hcsb5cyxxwz',\n",
    "    'jvj53cg6gm44jattfxws849e',\n",
    "    'fqebjziam9e7e9vnpzqghiv9',\n",
    "    'lwk7rgfebcajlfttz1f3euzs',\n",
    "    'b1c6cj5oy3wv9sh4qyj379s9',\n",
    "    'in6dp60i65swuwbnbyjz8m6i',\n",
    "    's7qczd3ccbwvvv54rkg2s3xh',\n",
    "    '3y3tn37wv2libdutqxbcat3d',\n",
    "    'p1h1eval1q08k2beesprnfwq'\n",
    "]\n",
    "for task_name in tasks:\n",
    "    print(task_name)\n",
    "    tdff = task_dat[task_name]\n",
    "\n",
    "    if len(tdff.filter(pl.col('sub_id').is_in(bad_subids))):\n",
    "        print(len(tdff.filter(pl.col('sub_id').is_in(bad_subids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60865bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for task_name in tasks:\n",
    "#     low_limit, high_limit = limits[task_name]\n",
    "#     tdf = addl_task_dat[task_name]\n",
    "#     if task_name == 'bart':\n",
    "#         tdff = tdf.with_columns(\n",
    "#             pl.when((pl.col('rt') > low_limit) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('og_mask')\n",
    "#         )\n",
    "#     else:\n",
    "#         tdff = tdf.with_columns(\n",
    "#             pl.when((pl.col('rt') > low_limit) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('og_mask'),\n",
    "#             pl.when((pl.col('rt') > low_limit) & (pl.col('rt') < high_limit)).then(True).otherwise(False).alias('bc_mask')\n",
    "#         ).with_columns(\n",
    "#             bc_mask=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: boxcoxmask(x), return_dtype=pl.Boolean).over(pl.col('sub_id')),\n",
    "#         ).with_columns(\n",
    "#             bc_rt=pl.when(pl.col('bc_mask')).then(pl.col('rt')).map_batches(lambda x: nanboxcox(x), return_dtype=pl.Float64).fill_nan(None).over(pl.col('sub_id')),\n",
    "#         ).with_columns(\n",
    "#             bc_z_rt=pl.when(pl.col('bc_mask')).then((pl.col('rt') - pl.col('rt').mean()) / pl.col('rt').std()).over(pl.col('sub_id'))\n",
    "#         )\n",
    "#     addl_task_dat[task_name] = tdff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not from_scratch:\n",
    "#     for task_name in tasks: \n",
    "#         tdf = task_dat[task_name]\n",
    "#         atdf = addl_task_dat[task_name]\n",
    "#         ctdf = pl.concat([tdf, atdf], how='diagonal_relaxed')\n",
    "#         task_dat[task_name] = ctdf\n",
    "# else:\n",
    "#     for task_name in tasks:\n",
    "#         task_dat[task_name] = addl_task_dat[task_name]\n",
    "\n",
    "# complete = []\n",
    "# for task_name in tasks:\n",
    "#     tdf = task_dat[task_name]\n",
    "#     expected_n = 2\n",
    "#     if task_name== 'rdm':\n",
    "#         expected_n = 3\n",
    "#     tmp = (tdf.group_by('sub_id').n_unique()\n",
    "#         .select(['sub_id', 'zrn']).with_columns(\n",
    "#             (pl.col('zrn')==expected_n).alias(f'has_all_{task_name}')\n",
    "#             ).select(['sub_id', f'has_all_{task_name}']))\n",
    "#     complete.append(tmp)\n",
    "# complete = pl.concat(complete, how='align').with_columns(\n",
    "#     has_all=(pl.col('has_all_flkr') & pl.col('has_all_cab') & pl.col('has_all_rdm') & pl.col('has_all_bart'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # double check that exclusion criteria are correct\n",
    "# for task_name in tasks:\n",
    "#     if task_name != 'bart':\n",
    "#         tdff = task_dat[task_name]\n",
    "#         # check that time limits are respected\n",
    "#         assert (tdff.filter(~pl.col('og_mask') & pl.col('bc_mask'))).is_empty()\n",
    "#         assert (tdff.filter(pl.col('bc_mask')).min().select('rt') > limits[task_name][0])[0, 'rt']\n",
    "#         assert (tdff.filter(pl.col('bc_mask')).max().select('rt') < limits[task_name][1])[0, 'rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc063ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in tasks:\n",
    "    old_task_dat = pl.read_parquet(data_dir/f'{task_name}.parquet')\n",
    "    tdff = task_dat[task_name]\n",
    "    if tdff.equals(old_task_dat):\n",
    "        continue\n",
    "    else:\n",
    "        old_task_dat.write_parquet(data_dir/f'{task_name}_old.parquet')\n",
    "        tdff.write_parquet(data_dir/f'{task_name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15860ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process subject level exclusion\n",
    "# subjects are excluded if:\n",
    "# 1) they have below chance performance\n",
    "# 2) > 5 or 10 % of trials are non-response or exluded by box-cox\n",
    "# bc_mask is true if the trial is within RT response bounds, has a response, and passed box-cox outlier exclusion\n",
    "tkeeps = []\n",
    "for task_name in tasks:\n",
    "    if task_name == 'cab':\n",
    "        task_dat[task_name] = task_dat[task_name].with_columns(\n",
    "            (pl.col('resp_acc') == True).alias('correct')\n",
    "        )\n",
    "    tdff = task_dat[task_name]\n",
    "    \n",
    "    if task_name == 'rdm':\n",
    "        tkeep = tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        tdff = tdff.with_columns(coh_dif=(pl.col('left_coherence') - pl.col('right_coherence')).abs())\n",
    "        tcorr = tdff.filter(pl.col('coh_dif') > 0).group_by(pl.col('sub_id')).sum().select(['sub_id','correct'])\n",
    "        tkeep = tkeep.join(tcorr, how='left', on='sub_id')\n",
    "    elif task_name == 'bart':\n",
    "        tkeep = tdff.group_by(['sub_id', 'zrn', 'balloon_id', 'date']).first().with_columns(\n",
    "            correct=pl.col('key_pressed') == pl.col('pump_button')\n",
    "        ).group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        ).with_columns(\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}')\n",
    "        ).with_columns(\n",
    "            pl.col(f'corr_ok_{task_name}').alias(f'good_{task_name}')\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good_{task_name}')).alias(f'bad_{task_name}')\n",
    "        ).rename({'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "    else:\n",
    "        tkeep =  tdff.group_by(pl.col('sub_id')).agg(\n",
    "            pl.sum('bc_mask').alias('bc_mask'),\n",
    "            pl.sum('correct').alias('correct'),\n",
    "            pl.last('date').alias('date')\n",
    "        )\n",
    "        \n",
    "    if task_name != 'bart':\n",
    "        tkeep = tkeep.with_columns(\n",
    "            (pl.col('bc_mask') >= rt05_threshes[task_name]).alias(f'resp05_ok_{task_name}'),\n",
    "            (pl.col('bc_mask') >= rt10_threshes[task_name]).alias(f'resp10_ok_{task_name}'),\n",
    "            (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (pl.col(f'resp05_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good05_{task_name}'),\n",
    "            (pl.col(f'resp10_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good10_{task_name}'),\n",
    "        ).with_columns(\n",
    "            (~pl.col(f'good05_{task_name}')).alias(f'bad05_{task_name}'),\n",
    "            (~pl.col(f'good10_{task_name}')).alias(f'bad10_{task_name}')\n",
    "        ).rename({\n",
    "            'bc_mask':f'n_good_resps_{task_name}', 'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "\n",
    "    tkeeps.append(tkeep)\n",
    "\n",
    "tkeep = pl.concat(tkeeps, how=\"align\").with_columns(\n",
    "    good05=(pl.col('good05_flkr') & pl.col('good_bart') & pl.col('good05_rdm') & pl.col('good05_cab')),\n",
    "    good10=(pl.col('good10_flkr') & pl.col('good_bart') & pl.col('good10_rdm') & pl.col('good10_cab')),\n",
    ").with_columns(\n",
    "    bad05=~pl.col('good05'),\n",
    "    bad10=~pl.col('good10')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d50eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tkeeps = []\n",
    "# for task_name in tasks:\n",
    "#     if task_name == 'cab':\n",
    "#         task_dat[task_name] = task_dat[task_name].with_columns(\n",
    "#             (pl.col('resp_acc') == True).alias('correct')\n",
    "#         )\n",
    "#     tdff = task_dat[task_name]\n",
    "    \n",
    "#     if task_name == 'rdm':\n",
    "#         tkeep = tdff.group_by(pl.col('sub_id')).agg(\n",
    "#             pl.sum('bc_mask').alias('bc_mask'),\n",
    "#             pl.sum('og_mask').alias('og_mask'),\n",
    "#             pl.last('date').alias('date')\n",
    "#         )\n",
    "#         tdff = tdff.with_columns(coh_dif=(pl.col('left_coherence') - pl.col('right_coherence')).abs())\n",
    "#         tcorr = tdff.filter(pl.col('coh_dif') > 0).group_by(pl.col('sub_id')).sum().select(['sub_id','correct'])\n",
    "#         tkeep = tkeep.join(tcorr, how='left', on='sub_id')\n",
    "#     elif task_name == 'bart':\n",
    "#         tkeep = tdff.group_by(['sub_id', 'zrn', 'balloon_id', 'date']).first().with_columns(\n",
    "#             correct=pl.col('key_pressed') == pl.col('pump_button')\n",
    "#         ).group_by(pl.col('sub_id')).agg(\n",
    "#             pl.sum('correct').alias('correct'),\n",
    "#             pl.last('date').alias('date')\n",
    "#         ).with_columns(\n",
    "#             (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}')\n",
    "#         ).with_columns(\n",
    "#             pl.col(f'corr_ok_{task_name}').alias(f'good_{task_name}')\n",
    "#         ).with_columns(\n",
    "#             (~pl.col(f'good_{task_name}')).alias(f'bad_{task_name}')\n",
    "#         ).rename({'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "#     else:\n",
    "#         tkeep =  tdff.group_by(pl.col('sub_id')).agg(\n",
    "#             pl.sum('bc_mask').alias('bc_mask'),\n",
    "#             pl.sum('og_mask').alias('og_mask'),\n",
    "#             pl.sum('correct').alias('correct'),\n",
    "#             pl.last('date').alias('date')\n",
    "#         )\n",
    "        \n",
    "#     if task_name != 'bart':\n",
    "#         tkeep = tkeep.with_columns(\n",
    "#             (pl.col('og_mask') >= rt_threshes[task_name]).alias(f'ogrt_ok_{task_name}'),\n",
    "#             (pl.col('bc_mask') >= rt_threshes[task_name]).alias(f'rt_ok_{task_name}'),\n",
    "#             (pl.col('correct') >= corr_threshes[task_name]).alias(f'corr_ok_{task_name}'),\n",
    "#         ).with_columns(\n",
    "#             (pl.col(f'rt_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'good_{task_name}'),\n",
    "#             (pl.col(f'ogrt_ok_{task_name}') & pl.col(f'corr_ok_{task_name}')).alias(f'oggood_{task_name}')\n",
    "#         ).with_columns(\n",
    "#             (~pl.col(f'good_{task_name}')).alias(f'bad_{task_name}')\n",
    "#         ).rename({'og_mask':f'n_good_ogrts_{task_name}',\n",
    "#                    'bc_mask':f'n_good_rts_{task_name}', 'correct': f'n_correct_{task_name}', 'date':f'date_{task_name}'})\n",
    "\n",
    "#     tkeeps.append(tkeep)\n",
    "\n",
    "# tkeep = pl.concat(tkeeps, how=\"align\").with_columns(\n",
    "#     good=(pl.col('good_flkr') & pl.col('good_bart') & pl.col('good_rdm') & pl.col('good_cab')),\n",
    "#     oggood=(pl.col('oggood_flkr') & pl.col('good_bart') & pl.col('oggood_rdm') & pl.col('oggood_cab')),\n",
    "# ).with_columns(\n",
    "#     bad=~pl.col('good')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep = tkeep.join(complete.select(['sub_id', 'has_all']), on='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a data quality CSV for participant filtering\n",
    "tkeep.write_csv(task_tomodel_dir / 'data_quality.csv')\n",
    "# write out data for all subjects\n",
    "# no need to do this until we've finished preregistration\n",
    "# for task_name in tasks:\n",
    "#     tdf = task_dat[task_name]\n",
    "#     subjects = tdf.select('sub_id').unique().to_numpy().flatten()\n",
    "\n",
    "#     for sub_id in subjects:\n",
    "#         sdf = tdf.filter(pl.col('sub_id') == sub_id)\n",
    "#         sdf.write_csv(out_dir / f'{task_name}-{sub_id}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34633dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep = tkeep.with_columns(\n",
    "    good_any05=pl.col('good05_flkr') | pl.col('good05_cab') | pl.col('good05_rdm') | pl.col('good_bart'),\n",
    "    good_any10=pl.col('good10_flkr') | pl.col('good10_cab') | pl.col('good10_rdm') | pl.col('good_bart')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee5329",
   "metadata": {},
   "source": [
    "# Count completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.select('date_flkr').min(), tkeep.select('date_flkr').max(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.select('good_any05').sum(), tkeep.select('good_any10').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "3659 / 4069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).sum().select(['good05', 'good10']), tkeep.filter(pl.col('has_all')).mean().select(['good05', 'good10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).sum().select(['good05', 'good10']), tkeep.filter(pl.col('has_all')).mean().select(['good05', 'good10'])and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).select(['good05', 'good05_flkr', 'good05_cab', 'good_bart', 'good05_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good05', 'good05_flkr', 'good05_cab', 'good_bart', 'good05_rdm', 'has_all']).sum(), tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm', 'has_all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82818b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3460ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).select(['good05', 'good05_flkr', 'good05_cab', 'good_bart', 'good05_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good05', 'good05_flkr', 'good05_cab', 'good_bart', 'good05_rdm', 'has_all']).sum(), tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm', 'has_all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d51163",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good10', 'good10_flkr', 'good10_cab', 'good_bart', 'good10_rdm', 'has_all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).select(['good', 'good_flkr', 'good_cab', 'good_bart', 'good_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good', 'good_flkr', 'good_cab', 'good_bart', 'good_rdm', 'has_all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.filter(pl.col('has_all')).select(['good', 'good_flkr', 'good_cab', 'good_bart', 'good_rdm']).mean(), tkeep.filter(pl.col('has_all')).select(['good', 'good_flkr', 'good_cab', 'good_bart', 'good_rdm', 'has_all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeep.sum().select('has_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e0e2f",
   "metadata": {},
   "source": [
    "# load survey responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_resps = [load_survey(sr_path) for sr_path in complete_dir.glob(\"*.json\")]\n",
    "srdf = proc_survey(survey_resps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_cols = [\n",
    "    'experience_depression',\n",
    "    'experience_anxiety',\n",
    "    'have_adhd',\n",
    "    'mentalhealth_daily_impact',\n",
    "    'screen_group',\n",
    "    'mood_pro_diagnosis',\n",
    "    'anxiety_pro_diagnosis',\n",
    "    'attention_pro_diagnosis'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stkeep = tkeep.join(srdf.select(['sub_id', 'survey_date'] + screen_cols), how='inner', on='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8054295",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep = stkeep.filter('has_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep = cstkeep.with_columns(\n",
    "        final_block_date=cstkeep.select(['date_flkr', 'date_bart', 'date_rdm', 'date_cab']).max_horizontal()\n",
    "    ).with_columns(\n",
    "        st_lag = (pl.col('final_block_date') - pl.col('survey_date')).dt.total_minutes()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep.select('st_lag').describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f94a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_order = ['hv', 'dep', 'anx', 'atn', 'dep_anx', 'dep_atn', 'anx_atn', 'dep_anx_atn', 'othermh']\n",
    "order_mapping = {val: i for i, val in enumerate(group_order)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep.group_by('screen_group').agg([\n",
    "    pl.sum('good10').alias('n_good'),\n",
    "    pl.sum('has_all').alias('n_complete'),\n",
    "    pl.mean('good10').alias('frac_good').round(2),\n",
    "    ]).sort(pl.col(\"screen_group\").replace(order_mapping)), 'foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep.group_by('screen_group').agg([\n",
    "    pl.sum('good').alias('n_good'),\n",
    "    pl.sum('has_all').alias('n_complete'),\n",
    "    pl.mean('good').alias('frac_good').round(2),\n",
    "    ]).sort(pl.col(\"screen_group\").replace(order_mapping)), 'foo'and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.chi2_contingency(cstkeep.group_by('screen_group').agg([\n",
    "    pl.sum('good10').alias('n_good'),\n",
    "    pl.sum('has_all').alias('n_complete')]).sort(pl.col(\"screen_group\").replace(order_mapping)).select(['n_good', 'n_complete']).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_good = cstkeep.sort(pl.col('final_block_date')).group_by_dynamic('final_block_date', every='1d').agg(\n",
    "    pl.col('good10').sum().alias(\"daily_n_good\"),\n",
    "    pl.col('has_all').sum().alias(\"daily_n_complete\"),\n",
    "    pl.col('good10').mean().alias(\"daily_good_rate\"),\n",
    ").with_columns(\n",
    "    pl.col('final_block_date').sub(start_time).dt.total_days().alias('study_day'),\n",
    "    tng:=pl.col('daily_n_good').cum_sum().alias('total_n_good'),\n",
    "    tnc:=pl.col('daily_n_complete').cum_sum().alias('total_n_complete'),\n",
    "    (tng/tnc).alias('total_good_rate')\n",
    ").with_columns(\n",
    "    pl.when(pl.col('study_day')>=14).then(pl.col('study_day')-11).otherwise('study_day').alias('study_day')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1,c2,c3,c4 = sns.color_palette('Paired', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, lax = plt.subplots(1)\n",
    "lax.plot(overall_good['study_day'], overall_good['total_n_complete'], color=c2, label='n_complete')\n",
    "lax.plot(overall_good['study_day'], overall_good['total_n_good'], color=c4, label='n_good')\n",
    "\n",
    "rax = lax.twinx()\n",
    "sns.barplot(data=overall_good, x='study_day', y='daily_n_complete',  color=c1, ax=rax)\n",
    "sns.barplot(data=overall_good, x='study_day', y='daily_n_good',color=c3, ax=rax)\n",
    "rax.set_zorder(0)\n",
    "lax.set_zorder(100)\n",
    "lax.patch.set_alpha(0)\n",
    "lax.set_ylabel('Total Counts (lines)')\n",
    "rax.set_ylabel('Daily Counts (bars)')\n",
    "lax.set_xlabel('Study Day')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "cstkeep.sort(pl.col('final_block_date')).group_by_dynamic('final_block_date', every='1d', group_by='screen_group').agg(\n",
    "    pl.col('good').sum().alias(\"n_good\"),\n",
    "    pl.col('has_all').sum().alias(\"n_complete\"),\n",
    "    pl.col('good').mean().alias(\"good_rate\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d230e",
   "metadata": {},
   "source": [
    "# add in prolific info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = (\n",
    "    pl.read_csv(data_dir / 'sid_prolific_demo.tsv', separator='\\t')\n",
    "    .filter(pl.col('status') != 'Status')\n",
    "    .filter(pl.col('sub_id').is_not_null())\n",
    "    .group_by('sub_id').last()\n",
    "    .with_columns(\n",
    "        pl.when(pl.col('depression') == \"Yes\").then(True).when(pl.col('depression') == \"No\").then(False).alias('depression'),\n",
    "        pl.when(pl.col('anxiety') == \"Yes\").then(True).when(pl.col('anxiety') == \"No\").then(False).alias('anxiety'),\n",
    "        pl.when(pl.col('attention') == \"Yes\").then(True).when(pl.col('attention') == \"No\").then(False).alias('attention'),\n",
    "        pl.when(pl.col('mental_health_ongoing') == \"Yes\").then(True).when(pl.col('mental_health_ongoing') == \"No\").then(False).alias('mental_health_ongoing'),\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2687e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkeep = pdf.join(cstkeep, how='right', on='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkeep['depression'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10358496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkeep = pkeep.with_columns(\n",
    "        p_screen_group=pl.when(\n",
    "            ~pl.col(\"mental_health_ongoing\")\n",
    "            & ~pl.col(\"depression\")\n",
    "            & ~pl.col(\"anxiety\")\n",
    "            & ~pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"hv\"))\n",
    "        .when(\n",
    "            pl.col(\"mental_health_ongoing\")\n",
    "            & ~pl.col(\"depression\")\n",
    "            & ~pl.col(\"anxiety\")\n",
    "            & ~pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"othermh\"))\n",
    "        .when(\n",
    "            pl.col(\"depression\")\n",
    "            & ~pl.col(\"anxiety\")\n",
    "            & ~pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"dep\"))\n",
    "        .when(\n",
    "            ~pl.col(\"depression\")\n",
    "            & pl.col(\"anxiety\")\n",
    "            & ~pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"anx\"))\n",
    "        .when(\n",
    "            ~pl.col(\"depression\")\n",
    "            & ~pl.col(\"anxiety\")\n",
    "            & pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"atn\"))\n",
    "        .when(\n",
    "            pl.col(\"depression\")\n",
    "            & pl.col(\"anxiety\")\n",
    "            & ~pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"dep_anx\"))\n",
    "        .when(\n",
    "            pl.col(\"depression\")\n",
    "            & ~pl.col(\"anxiety\")\n",
    "            & pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"dep_atn\"))\n",
    "        .when(\n",
    "            ~pl.col(\"depression\")\n",
    "            & pl.col(\"anxiety\")\n",
    "            & pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"anx_atn\"))\n",
    "        .when(\n",
    "            pl.col(\"depression\")\n",
    "            & pl.col(\"anxiety\")\n",
    "            & pl.col(\"attention\")\n",
    "        )\n",
    "        .then(pl.lit(\"dep_anx_atn\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_atn = pkeep.group_by(['p_screen_group', 'screen_group']).agg([\n",
    "    pl.sum('good').alias('n_good'),\n",
    "    pl.sum('has_all').alias('n_complete'),\n",
    "    pl.mean('good').alias('frac_good').round(2),\n",
    "    ]).sort(pl.col(\"p_screen_group\").replace(order_mapping)).filter(pl.col(\"p_screen_group\") == 'atn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_atn = pkeep.filter((pl.col('p_screen_group')=='atn') & (pl.col('status')==\"APPROVED\")).with_columns(\n",
    "    is_atn=pl.col('screen_group') == 'atn',\n",
    "    is_good_atn = (pl.col('screen_group') == 'atn') & pl.col('good')\n",
    ")\n",
    "p_atn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0809378",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_atn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_atn.group_by('screen_group').agg([\n",
    "    pl.sum('good').alias('n_good') / 35,\n",
    "    pl.sum('has_all').alias('n_complete'),\n",
    "    pl.mean('good').alias('frac_good').round(2),\n",
    "    ]).sort(pl.col(\"screen_group\").replace(order_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da18931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkeep.group_by(['screen_group', 'p_screen_group']).agg([\n",
    "    pl.sum('good').alias('n_good'),\n",
    "    pl.sum('has_all').alias('n_complete'),\n",
    "    pl.mean('good').alias('frac_good').round(2),\n",
    "    ]).sort(pl.col(\"screen_group\").replace(order_mapping)).filter(pl.col(\"screen_group\") == 'atn'), 'foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5a36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogmood-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
